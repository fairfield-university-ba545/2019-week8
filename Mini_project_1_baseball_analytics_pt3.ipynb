{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Project #1: Baseball Analytics\n",
    "\n",
    "The overall purpose of this mini-project is to predicting MLB wins per season by modeling data to KMeans clustering model and linear regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Analysis/Modeling\n",
    "\n",
    "In this part of the project, you are going to conduct actual analysis on the data your just processed in Part 1 & 2. The tasks in the part include:\n",
    "- K-means Clustering: pre-modeling part that provides insights toward the data;\n",
    "- Linear Regression: predict Wins (continuous) using trained linear regression model;\n",
    "- Logistic Regression: predict Win_bins (categorical) using trained logistic regression model __on your own__.\n",
    "\n",
    "Let's get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read-in required data\n",
    "# features for analysis\n",
    "data_features = pd.read_csv('../data/baseball_analytics_features.csv', header=0, index_col=0)\n",
    "\n",
    "# continuous target `wins`\n",
    "wins = pd.read_csv('../data/baseball_analytics_wins.csv',  index_col=0, names = ['wins'])\n",
    "\n",
    "# categorical target `Win_bins`\n",
    "win_bins = pd.read_csv('../data/baseball_analytics_target.csv',  index_col=0, names = ['win_bins'])\n",
    "\n",
    "# display if data are read correctly\n",
    "print(data_features.head())\n",
    "print(wins.head())\n",
    "print(win_bins.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means Clustering\n",
    "\n",
    "K-means clustering, as a basic clustering technique, can capture internal relationship(s) between your data points. Sometimes we use (k-means) clustering as a pre-modeling step for supervised learning: essentially, we can use k-means clsutering to capture the internal relationship of the features, and then capture the relationship in an additional feature that being used as an input to a classification/regression model.\n",
    "\n",
    "One key step in k-means clustering is to determine the value of `k` - how many clusters? If we want to use the clustering results as an additional (categorical) feature, we should not have a higher value of `k`. Also, increasing value of `k` may increase the erroneous relationship being captured. The k-means model is provided in `sklearn.clustering`.\n",
    "\n",
    "In this tutorial, we use **Grid Search** to find the best value of `k`. To conduct Grid Search, you need a range of `k` and a metric that measures the performance under each value of `k`. In this context, we select the metric as the [**silhouette score**](https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html) (`s_score`), which is provided in `sklearn.metrics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Silhouette score is a visualized way of measuring the performance of clustering. Thus, we need to import `matplotlib` to visualize the clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and initialize matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to create a figure that contains different value of `k` as sub-figures\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "fig.subplots_adjust(left=0,right=1,bottom=0,top=1,hspace=0.05,wspace=0.5)\n",
    "\n",
    "#### complete your code below\n",
    "#### create an empty dictionary `s_score_dict` that we will use to store silhouette scores\n",
    "#### for different `k` values; use different `k` values as keys, and corresponding\n",
    "#### silhouette score as values\n",
    "\n",
    "\n",
    "#### now we create a for-loop go through a range of `k` values in [2, 11]\n",
    "for i in range(2,11):\n",
    "    #### add a sub-figure `ax` to `fig` using `.add_subplot(8,8,i+1,xticks=[],yticks=[])`\n",
    "    \n",
    "    # conduct the k-means clustering using `k = i`\n",
    "    km = KMeans(n_clusters=i, random_state=2019)\n",
    "    # any clustering model needs a distance metric, in this case, `distance` is the distance between\n",
    "    # any pair of data points\n",
    "    distances = km.fit_transform(data_features)\n",
    "    # clustering models will generate `labels` - if you want to create the additional feature \n",
    "    # as discussed above, you will use `labels` as its values\n",
    "    labels = km.labels_\n",
    "    # you will then applied the fitted `km` model to `data_faetures`\n",
    "    l= km.fit_predict(data_features)\n",
    "    # Silhouette score is computed between `data_features` and `l`\n",
    "    s_s= metrics.silhouette_score(data_features, l)\n",
    "    #### update the `s_score_dict` using `i` as key and `s_s` as value\n",
    "    \n",
    "    # we will plot the clusters out using scatter plot\n",
    "    plt.scatter(distances[:,0], distances[:,1], c=labels)\n",
    "    #### add 'i clusters' as the title of each sub-figure\n",
    "    \n",
    "    \n",
    "#### show plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually, we know that 2-clusters looks the best. Let's double check the silhouette score to make sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_score_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As observed in the figure, 2-cluster model returns the highest silhouette score. \n",
    "\n",
    "__Rule of thumb__: However, we normally start searching for `k` value at `3`.\n",
    "\n",
    "So we are going to build a k-means model of `k=3`, and then add the `cluster_label` as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### complete your code below\n",
    "#### create a model called `kmeans_model` with `n_clusters = 3` and `random_state = 2019`\n",
    "\n",
    "\n",
    "#### capture `distances` by fit (`fit_transform`) `kmeans_model` to `data_features`\n",
    "\n",
    "\n",
    "#### record labels of clusters in `labels`\n",
    "\n",
    "\n",
    "#### create a scatter plot (plt.scatter()) to plot the clusters\n",
    "\n",
    "\n",
    "#### add title to plot as `3-cluster plot`\n",
    "\n",
    "\n",
    "#### show the plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks pretty good, correct? Now let's add the `labels` to `data_features` as an additional feature so that we can use it in further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at `labels`\n",
    "print(labels)\n",
    "print(len(labels))\n",
    "print(data_features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### complete your code below\n",
    "#### add `labels` to `data_features`\n",
    "#### add `labels` as a column in `data_features` namely `label`\n",
    "\n",
    "\n",
    "#### double check by looking at the first 5 rows of `data_features`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "\n",
    "We will train linear regression models to predict a continuous target `wins`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### complete your code below\n",
    "#### first we need to create the dataset we will use for the regression model\n",
    "#### `reg_data` = `data_features` + `wins`\n",
    "\n",
    "\n",
    "#### double check by looking at the first 5 rows of `reg_data`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### complete your code below\n",
    "#### investigate descriptive stats using describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the dependencies for building and evaluation a linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import `LinearRegression` from `sklearn.linear_model`\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Import `mean_absolute_error` from `sklearn.metrics`\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's define the features and target. There are two ways of doing this. Let's try the first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### complete your code below\n",
    "#### create a variable `reg_values` which are the values in `reg_data`\n",
    "\n",
    "\n",
    "#### create a variable `X` which contains all columns in `reg_values` besides the last \n",
    "\n",
    "\n",
    "#### create a variable `y` which contains the last column in `reg_values`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an alternative method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### complete your code below\n",
    "#### create a variable `Xa` which contains all values in `data_features`\n",
    "\n",
    "\n",
    "#### create a variable `ya` which contains values in `wins`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to split our data into training (`X_train`, `y_train`) and testing (`X_test`, `y_test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### complete your code below\n",
    "#### import `train_test_split` from `sklearn.model_selection`\n",
    "\n",
    "\n",
    "#### split X, y into training and testing, using 75/25 split, and set `random_state = 2019`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Linear Regression model, fit model, and make predictions\n",
    "lr = LinearRegression(normalize=True)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the MAE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Print `mae`\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can print your linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try to train an advanced regression model to see if there is any improvement in results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import `RidgeCV` from `sklearn.linear_model`\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "# Create Ridge Linear Regression model, fit model, and make predictions\n",
    "rrm = RidgeCV(alphas=(0.01, 0.1, 1.0, 10.0), normalize=True)\n",
    "rrm.fit(X_train, y_train)\n",
    "predictions_rrm = rrm.predict(X_test)\n",
    "\n",
    "# Determine mean absolute error\n",
    "mae_rrm = mean_absolute_error(y_test, predictions_rrm)\n",
    "print(mae_rrm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see how much contribution the `label` feature provides to the regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Complete your code below\n",
    "#### create a variable `Xb` without `label`\n",
    "#### you can do it by getting X[:,:-1]\n",
    "\n",
    "#### create your training and testing data using Xb and y\n",
    "#### remember that Xb does not contain 'label', use the same parameters as before\n",
    "#### 75/25 split, and `random_state = 2019`\n",
    "\n",
    "\n",
    "#### Create Linear Regression model, fit model, and make predictions\n",
    "\n",
    "\n",
    "#### calculate the MAE\n",
    "\n",
    "\n",
    "#### Print `mae`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: \n",
    "__Do you observe an improvement or not while excluding `label` in the analysis? In other words, does `label` help with the analysis? Answer in the next block__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Double click and type your answer__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "You will need to create a logistic regression model __on your own__, using `data_features` as features, and `win_bins` as the target.\n",
    "\n",
    "If you have any question, refer to the logistic regression notebook for more help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
